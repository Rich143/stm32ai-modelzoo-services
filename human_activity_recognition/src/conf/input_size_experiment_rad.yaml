general:
  project_name: human_activity_recognition
  logs_dir: logs
  saved_models_dir: saved_models
  display_figures: True
  global_seed: 123
  gpu_memory_limit: 30
  deterministic_ops: True

operation_mode: experiment

experiment:
  name: "HAR_CNN_PAMAP2_RAD_HARTH"
  tags:
    sweep_axis: "input_len"
    model: ign
    study: "input_len_sweep"
  experiment_params:
    input_len_sweep_start: 40
    input_len_sweep_end: 60
    input_len_sweep_step: 4
    k_fold_validation: True # [True, False]
    num_runs_per_input_len: 2

dataset:
  names: [pamap2, harth, rad]
  paths: [../datasets/PAMAP2_Dataset, ../datasets/harth, ../datasets/rad]
  class_names: [stationary, walking, running, cycling]
  train_val_test_cv_split:
    test_subjects: [RAD_1, RAD_2, RAD_3]

    # Subjects to always be used for training, used to increase train set size compared to validation
    train_subjects: [HARTH_26, HARTH_27, HARTH_28, HARTH_29, HARTH_30,
    HARTH_31, HARTH_32, HARTH_33, HARTH_34]

    excluded_subjects: [] # Excluded subjects
  seed: 123               # Optional, there is a default seed

preprocessing:
  gravity_rot_sup: True
  gaussian_noise: True
  gaussian_std: 0.125 # m/s^2
  sample_rate: 50 # Hz
  mean_group_delay: 123 # Samples

training:
  model:
    name: ign # available choices are [ign, gmp]
    input_shape: (24, 3, 1)
  dropout: 0.2
  batch_size: 128
  epochs: 120
  steps_per_epoch: 5000
  optimizer:
    Adam:
      #learning_rate: 0.01
  callbacks:
    LRCosineDecay:
       initial_lr: 0.001   # Initial learning rate.
       hold_steps: 0      # The number of epochs to hold the learning rate constant between two drops.
       decay_steps: 50    # the number of steps to decay over following a cosine function
       end_lr: 1e-5        # The learning rate value reached at the end of the cosine decay phase. 
       verbose: 1          # Verbosity (0 or 1). If set to 1, the learning rate value is printed at the beginning of each epoch.
    EarlyStopping:
      monitor: val_accuracy
      restore_best_weights: true
      patience: 20

##  trained_model_path: trained.h5   # Optional, use it if you want to save the best model at the end of the training to a path of your choice

tools:
   stedgeai:
      version: 10.0.0
      optimization: balanced
      on_cloud: True
      #path_to_stedgeai: C:/Users/<XXXXX>/STM32Cube/Repository/Packs/STMicroelectronics/X-CUBE-AI/<*.*.*>/Utilities/windows/stedgeai.exe
      #path_to_stedgeai: /Applications/STMicroelectronics/STM32CubeMX.app/Contents/MacOs/STM32CubeMX/
      path_to_stedgeai: ~/STM32Cube/Repository/Packs/STMicroelectronics/X-CUBE-AI/8.1.0
   path_to_cubeIDE: /Applications/STM32CubeIDE.app/Contents/MacOS/STM32CubeIDE

benchmarking:
  board: B-U585I-IOT02A

deployment:
  c_project_path: ../../stm32ai_application_code/sensing_thread_x/
  IDE: GCC
  verbosity: 1
  hardware_setup:
    serie: STM32U5
    board: B-U585I-IOT02A

mlflow:
  uri: http://127.0.0.1:5000

hydra:
  run:
    dir: ./experiments_outputs/${now:%Y_%m_%d_%H_%M_%S}
